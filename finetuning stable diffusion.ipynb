{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14106566,"sourceType":"datasetVersion","datasetId":8984940}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/dhruv836/lora-training?scriptVersionId=287297527\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# Clone the repository and install dependencies\n!git clone https://github.com/bmaltais/kohya_ss.git\n%cd kohya_ss\n\n# This installation script handles all the heavy lifting\n!./setup.sh -n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T16:13:59.210287Z","iopub.execute_input":"2025-12-19T16:13:59.210522Z","iopub.status.idle":"2025-12-19T16:21:04.382674Z","shell.execute_reply.started":"2025-12-19T16:13:59.210497Z","shell.execute_reply":"2025-12-19T16:21:04.381965Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport shutil\nfrom glob import glob\n\n# --- CONFIGURATION ---\nproject_name = \"slide_revamp_project\"\ntrigger_word = \"slidestyl\" \nclass_word = \"background\" \nrepeats = 100 \n\n# Use the path you copied from the sidebar (without .zip)\n# If you are unsure, just use the root input folder, my script will find the images.\ninput_dataset_path = \"/kaggle/input\" \n\n# --- SETUP DIRECTORIES ---\nroot_dir = f\"/kaggle/working/{project_name}\"\nimg_dir = f\"{root_dir}/img/{repeats}_{trigger_word} {class_word}\"\nreg_dir = f\"{root_dir}/reg\"\nmodel_dir = f\"{root_dir}/model\"\nlog_dir = f\"{root_dir}/log\"\n\nfor d in [img_dir, reg_dir, model_dir, log_dir]:\n    os.makedirs(d, exist_ok=True)\n\n# --- SMART COPY SCRIPT ---\nprint(f\"Scanning for images in {input_dataset_path}...\")\nimage_count = 0\n\n# Walk through the entire input directory to find images\nfor root, dirs, files in os.walk(input_dataset_path):\n    for file in files:\n        # Check if the file is an image\n        if file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n            source_path = os.path.join(root, file)\n            destination_path = os.path.join(img_dir, file)\n            \n            # Copy the file\n            shutil.copy2(source_path, destination_path)\n            image_count += 1\n\nif image_count == 0:\n    print(\"ERROR: No images found! Please check your dataset path.\")\nelse:\n    print(f\"SUCCESS: Found and moved {image_count} images to: {img_dir}\")\n    print(\"You are ready for Cell 4 (Captioning).\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T16:21:51.484267Z","iopub.execute_input":"2025-12-19T16:21:51.484883Z","iopub.status.idle":"2025-12-19T16:21:51.812152Z","shell.execute_reply.started":"2025-12-19T16:21:51.484851Z","shell.execute_reply":"2025-12-19T16:21:51.811403Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\n# 1. Define the path to the problematic file based on your error log\nblip_file_path = \"/kaggle/working/kohya_ss/sd-scripts/finetune/blip/blip.py\"\n\nif os.path.exists(blip_file_path):\n    # 2. Read the file\n    with open(blip_file_path, \"r\") as f:\n        lines = f.readlines()\n\n    # 3. Rewrite the file, commenting out the strict assertion\n    with open(blip_file_path, \"w\") as f:\n        patched = False\n        for line in lines:\n            # This is the line causing the crash\n            if \"assert(len(msg.missing_keys)==0)\" in line:\n                f.write(\"# \" + line) # We add a # to turn it into a comment\n                patched = True\n            else:\n                f.write(line)\n    \n    if patched:\n        print(\"SUCCESS: Patch applied! The strict check has been disabled.\")\n    else:\n        print(\"WARNING: Could not find the line to patch. Was it already fixed?\")\nelse:\n    print(f\"ERROR: Could not find file at {blip_file_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T16:24:54.453142Z","iopub.execute_input":"2025-12-19T16:24:54.453458Z","iopub.status.idle":"2025-12-19T16:24:54.460094Z","shell.execute_reply.started":"2025-12-19T16:24:54.453435Z","shell.execute_reply":"2025-12-19T16:24:54.459304Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport subprocess\n\n# --- CONFIGURATION ---\nproject_name = \"slide_revamp_project\"\ntrigger_word = \"slidestyl\"\nimg_dir = f\"/kaggle/working/{project_name}/img/100_{trigger_word} background\"\nwork_dir = \"/kaggle/working/kohya_ss/sd-scripts\"\nscript_path = os.path.join(work_dir, \"finetune\", \"make_captions.py\")\n\n# --- RUN CAPTIONING ---\nprint(f\"Starting BLIP captioning...\")\n\ncommand = [\n    \"python\", script_path,\n    \"--batch_size\", \"8\",\n    \"--caption_extension\", \".txt\",\n    \"--caption_weights\", \"https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_base_capfilt_large.pth\",\n    img_dir\n]\n\nresult = subprocess.run(command, cwd=work_dir, capture_output=True, text=True)\n\nif result.returncode != 0:\n    print(\"Captioning Failed. Error log:\")\n    print(result.stderr)\nelse:\n    print(\"BLIP captioning successful!\")\n\n    # --- ADD TRIGGER WORD ---\n    print(f\"Adding trigger word '{trigger_word}' to all captions...\")\n    txt_files = [f for f in os.listdir(img_dir) if f.endswith(\".txt\")]\n    \n    for file in txt_files:\n        file_path = os.path.join(img_dir, file)\n        with open(file_path, 'r') as f:\n            original_caption = f.read().strip()\n        with open(file_path, 'w') as f:\n            f.write(f\"{trigger_word} style, {original_caption}\")\n            \n    print(f\"Processed {len(txt_files)} files.\")\n    print(\"Verification (First file):\")\n    os.system(f'ls \"{img_dir}\"/*.txt | head -n 1 | xargs cat')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T16:24:57.939565Z","iopub.execute_input":"2025-12-19T16:24:57.94026Z","iopub.status.idle":"2025-12-19T16:25:57.761154Z","shell.execute_reply.started":"2025-12-19T16:24:57.940231Z","shell.execute_reply":"2025-12-19T16:25:57.760351Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shutil\nfrom IPython.display import FileLink\n\n# 1. Define the folder we want to zip (where your images and txt files are)\n# (Using the variables from previous cells)\nproject_name = \"slide_revamp_project\"\ntrigger_word = \"slidestyl\"\nsource_folder = f\"/kaggle/working/{project_name}/img/100_{trigger_word} background\"\noutput_filename = \"dataset_with_captions\"\n\n# 2. Create the zip file\nprint(f\"Zipping folder: {source_folder}...\")\nshutil.make_archive(output_filename, 'zip', source_folder)\n\nprint(\"Zip created successfully!\")\n\n# 3. Create a clickable download link\nFileLink(f\"{output_filename}.zip\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-11T12:10:13.551935Z","iopub.execute_input":"2025-12-11T12:10:13.552496Z","iopub.status.idle":"2025-12-11T12:10:13.599537Z","shell.execute_reply.started":"2025-12-11T12:10:13.552461Z","shell.execute_reply":"2025-12-11T12:10:13.598838Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Start the GUI\n!python ./kohya_gui.py --share --headless","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T16:25:57.762378Z","iopub.execute_input":"2025-12-19T16:25:57.762676Z","iopub.status.idle":"2025-12-19T20:11:09.777312Z","shell.execute_reply.started":"2025-12-19T16:25:57.762655Z","shell.execute_reply":"2025-12-19T20:11:09.776526Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shutil\n\nshutil.make_archive(\n    '/kaggle/working/slide_revamp_project/img/',\n    'zip',\n    '/kaggle/working/slide_revamp_project/img/'\n)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T20:15:15.578898Z","iopub.execute_input":"2025-12-19T20:15:15.57977Z","iopub.status.idle":"2025-12-19T20:15:15.623033Z","shell.execute_reply.started":"2025-12-19T20:15:15.579743Z","shell.execute_reply":"2025-12-19T20:15:15.622487Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!ls /kaggle/working/slide_revamp_project\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T20:19:37.230943Z","iopub.execute_input":"2025-12-19T20:19:37.231584Z","iopub.status.idle":"2025-12-19T20:19:37.348075Z","shell.execute_reply.started":"2025-12-19T20:19:37.231553Z","shell.execute_reply":"2025-12-19T20:19:37.347377Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\nzip_path = \"/kaggle/working/slide_revamp_project/img.zip\"\nprint(\"Exists:\", os.path.exists(zip_path))\nprint(\"Size:\", os.path.getsize(zip_path) / (1024*1024), \"MB\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T20:23:22.507375Z","iopub.execute_input":"2025-12-19T20:23:22.507965Z","iopub.status.idle":"2025-12-19T20:23:22.512817Z","shell.execute_reply.started":"2025-12-19T20:23:22.507906Z","shell.execute_reply":"2025-12-19T20:23:22.512077Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}