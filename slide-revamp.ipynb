{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14180471,"sourceType":"datasetVersion","datasetId":9039953},{"sourceId":14180786,"sourceType":"datasetVersion","datasetId":9040203},{"sourceId":14228951,"sourceType":"datasetVersion","datasetId":9077532},{"sourceId":14259661,"sourceType":"datasetVersion","datasetId":9099023}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/dhruv836/slide-revamp?scriptVersionId=287862086\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"!pip install python-pptx lxml\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T18:01:00.909111Z","iopub.execute_input":"2025-12-22T18:01:00.909493Z","iopub.status.idle":"2025-12-22T18:01:02.383384Z","shell.execute_reply.started":"2025-12-22T18:01:00.909453Z","shell.execute_reply":"2025-12-22T18:01:02.382677Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install torch torchvision==0.15.2 torchaudio --index-url https://download.pytorch.org/whl/cu118\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T18:01:02.384815Z","iopub.execute_input":"2025-12-22T18:01:02.385018Z","iopub.status.idle":"2025-12-22T18:01:04.26755Z","shell.execute_reply.started":"2025-12-22T18:01:02.384998Z","shell.execute_reply":"2025-12-22T18:01:04.26663Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!pip install torchvision==0.15.2 --force-reinstall --no-cache-dir\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T18:01:04.268797Z","iopub.execute_input":"2025-12-22T18:01:04.269048Z","iopub.status.idle":"2025-12-22T18:01:04.272754Z","shell.execute_reply.started":"2025-12-22T18:01:04.269023Z","shell.execute_reply":"2025-12-22T18:01:04.27205Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"run the above cell first because,it will install a version of numpy which is not compatible with our models so the next will change to appropraite version","metadata":{}},{"cell_type":"code","source":"!pip install --upgrade pip setuptools wheel\n!pip install numpy==1.26.4 scipy==1.11.4\n!pip install matplotlib==3.8.2\n!pip install filterpy facexlib basicsr\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T18:01:04.273824Z","iopub.execute_input":"2025-12-22T18:01:04.27407Z","iopub.status.idle":"2025-12-22T18:01:12.3052Z","shell.execute_reply.started":"2025-12-22T18:01:04.274052Z","shell.execute_reply":"2025-12-22T18:01:12.304533Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nimport os\nos.listdir(\"/kaggle/working/\")\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T18:01:12.307506Z","iopub.execute_input":"2025-12-22T18:01:12.307758Z","iopub.status.idle":"2025-12-22T18:01:12.313676Z","shell.execute_reply.started":"2025-12-22T18:01:12.307734Z","shell.execute_reply":"2025-12-22T18:01:12.312999Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# for taking input\nPPTX_PATH = \"/kaggle/input/sample-4/sample4.pptx\"\nUSER_PROMPT = \"colorful\"\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T18:20:16.073038Z","iopub.execute_input":"2025-12-22T18:20:16.073389Z","iopub.status.idle":"2025-12-22T18:20:16.077214Z","shell.execute_reply.started":"2025-12-22T18:20:16.073363Z","shell.execute_reply":"2025-12-22T18:20:16.076538Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nassert os.path.exists(PPTX_PATH)\nprint(\"PPTX found \")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T18:20:17.577025Z","iopub.execute_input":"2025-12-22T18:20:17.577712Z","iopub.status.idle":"2025-12-22T18:20:17.607474Z","shell.execute_reply.started":"2025-12-22T18:20:17.577688Z","shell.execute_reply":"2025-12-22T18:20:17.606684Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!git clone https://github.com/dhruv8361343/SlideRevamp.git","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T18:01:12.351804Z","iopub.execute_input":"2025-12-22T18:01:12.352128Z","iopub.status.idle":"2025-12-22T18:01:12.477966Z","shell.execute_reply.started":"2025-12-22T18:01:12.352103Z","shell.execute_reply":"2025-12-22T18:01:12.477159Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import sys\nsys.path.append(\"/kaggle/working/SlideRevamp\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T18:01:12.478953Z","iopub.execute_input":"2025-12-22T18:01:12.479469Z","iopub.status.idle":"2025-12-22T18:01:12.482752Z","shell.execute_reply.started":"2025-12-22T18:01:12.479446Z","shell.execute_reply":"2025-12-22T18:01:12.482208Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from pptx_extractor import extract\nfrom content_refinement import refine_content\n\nprint(\"Imports successful \")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T18:01:12.483361Z","iopub.execute_input":"2025-12-22T18:01:12.483539Z","iopub.status.idle":"2025-12-22T18:01:16.869044Z","shell.execute_reply.started":"2025-12-22T18:01:12.483525Z","shell.execute_reply":"2025-12-22T18:01:16.868468Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from pptx_extractor import extract\nfrom pathlib import Path\n\nOUTPUT_DIR = Path(\"/kaggle/working/outputs\")\n\nextract(\n    pptx_path=PPTX_PATH,\n    out_dir=OUTPUT_DIR\n)\nprint(\"don\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T18:01:16.869698Z","iopub.execute_input":"2025-12-22T18:01:16.870069Z","iopub.status.idle":"2025-12-22T18:01:17.091149Z","shell.execute_reply.started":"2025-12-22T18:01:16.870052Z","shell.execute_reply":"2025-12-22T18:01:17.090598Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"STYLE_TOKEN = refine_content(\n    ingestion_output_dir=\"/kaggle/working/outputs\",\n    user_vibe=USER_PROMPT\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T18:20:24.428267Z","iopub.execute_input":"2025-12-22T18:20:24.428988Z","iopub.status.idle":"2025-12-22T18:20:43.573272Z","shell.execute_reply.started":"2025-12-22T18:20:24.428963Z","shell.execute_reply":"2025-12-22T18:20:43.572703Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# for saving our style token that we call in previous code block\nimport json\nfrom pathlib import Path\n\nSTYLE_PATH = Path(\"/kaggle/working/outputs/style_token.json\")\nSTYLE_PATH.write_text(\n    json.dumps(STYLE_TOKEN, indent=2),\n    encoding=\"utf-8\"\n)\n\nprint(\"Style token \")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T18:21:48.430194Z","iopub.execute_input":"2025-12-22T18:21:48.430508Z","iopub.status.idle":"2025-12-22T18:21:48.436115Z","shell.execute_reply.started":"2025-12-22T18:21:48.430487Z","shell.execute_reply":"2025-12-22T18:21:48.435541Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"now running the Real-ESRGAN model for image scaling can be used for upscaling the bbackground generated","metadata":{}},{"cell_type":"code","source":"!git clone https://github.com/xinntao/Real-ESRGAN.git\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T18:01:35.40808Z","iopub.execute_input":"2025-12-22T18:01:35.408272Z","iopub.status.idle":"2025-12-22T18:01:36.074037Z","shell.execute_reply.started":"2025-12-22T18:01:35.408256Z","shell.execute_reply":"2025-12-22T18:01:36.073193Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install -r Real-ESRGAN/requirements.txt --no-deps\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T18:01:36.07497Z","iopub.execute_input":"2025-12-22T18:01:36.075251Z","iopub.status.idle":"2025-12-22T18:01:37.100928Z","shell.execute_reply.started":"2025-12-22T18:01:36.075227Z","shell.execute_reply":"2025-12-22T18:01:37.100213Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install -e Real-ESRGAN\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T18:01:37.101927Z","iopub.execute_input":"2025-12-22T18:01:37.102195Z","iopub.status.idle":"2025-12-22T18:01:47.926197Z","shell.execute_reply.started":"2025-12-22T18:01:37.102171Z","shell.execute_reply":"2025-12-22T18:01:47.925446Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"for saving weights from input to output folder","metadata":{}},{"cell_type":"code","source":"!mkdir -p /kaggle/working/Real-ESRGAN/weights\n!cp /kaggle/input/weights/RealESRGAN_x4plus.pth /kaggle/working/Real-ESRGAN/weights/\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T18:01:47.927249Z","iopub.execute_input":"2025-12-22T18:01:47.927954Z","iopub.status.idle":"2025-12-22T18:01:49.933254Z","shell.execute_reply.started":"2025-12-22T18:01:47.927927Z","shell.execute_reply":"2025-12-22T18:01:49.932491Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!python Real-ESRGAN/inference_realesrgan.py -h\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T18:01:49.934412Z","iopub.execute_input":"2025-12-22T18:01:49.934701Z","iopub.status.idle":"2025-12-22T18:01:57.491459Z","shell.execute_reply.started":"2025-12-22T18:01:49.934669Z","shell.execute_reply":"2025-12-22T18:01:57.490762Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from image_processing.upscale import upscale_image\n\ntest_img = \"/kaggle/working/outputs/images/slide02_shape3_img.png\"\n\nupscaled = upscale_image(\n    image_path=test_img,\n    output_dir=\"/kaggle/working/outputs/images_upscaled\"\n)\n\nprint(\"Upscaled image:\", upscaled)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T18:01:57.492578Z","iopub.execute_input":"2025-12-22T18:01:57.492875Z","iopub.status.idle":"2025-12-22T18:02:03.44334Z","shell.execute_reply.started":"2025-12-22T18:01:57.492843Z","shell.execute_reply":"2025-12-22T18:02:03.442729Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"now the u-2-net model for image cropping(it provides mask for the most imp part of image and we will crop it using python script)","metadata":{}},{"cell_type":"code","source":"!git clone https://github.com/xuebinqin/U-2-Net.git","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T18:02:03.44405Z","iopub.execute_input":"2025-12-22T18:02:03.444243Z","iopub.status.idle":"2025-12-22T18:02:06.098556Z","shell.execute_reply.started":"2025-12-22T18:02:03.444226Z","shell.execute_reply":"2025-12-22T18:02:06.097866Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"transfering weights form input to output directory\n","metadata":{}},{"cell_type":"code","source":"!mkdir -p /kaggle/working/U-2-Net/saved_models/u2net\n!cp /kaggle/input/weights/u2net.pth /kaggle/working/U-2-Net/saved_models/u2net\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T18:02:06.099592Z","iopub.execute_input":"2025-12-22T18:02:06.099837Z","iopub.status.idle":"2025-12-22T18:02:11.192427Z","shell.execute_reply.started":"2025-12-22T18:02:06.099814Z","shell.execute_reply":"2025-12-22T18:02:11.191656Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"masking using u-2-net","metadata":{}},{"cell_type":"code","source":"from image_processing.mask import generate_mask\n\nmask = generate_mask(\n    image_path=upscaled,\n    output_dir=\"/kaggle/working/outputs/masks\"\n)\n\nprint(\"Mask generated:\", mask)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T18:02:11.193417Z","iopub.execute_input":"2025-12-22T18:02:11.193809Z","iopub.status.idle":"2025-12-22T18:02:16.218882Z","shell.execute_reply.started":"2025-12-22T18:02:11.19378Z","shell.execute_reply":"2025-12-22T18:02:16.218177Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"cropping ","metadata":{}},{"cell_type":"code","source":"from image_processing.smart_crop import smart_crop\nimport cv2\n\nfinal = smart_crop(\n    image_path=str(upscaled),\n    mask_path=str(mask)\n)\n\ncv2.imwrite(\n    \"/kaggle/working/outputs/images_final/final.png\",\n    final\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T18:02:16.219703Z","iopub.execute_input":"2025-12-22T18:02:16.219998Z","iopub.status.idle":"2025-12-22T18:02:16.305168Z","shell.execute_reply.started":"2025-12-22T18:02:16.219975Z","shell.execute_reply":"2025-12-22T18:02:16.304642Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"for running on all slides","metadata":{}},{"cell_type":"code","source":"from pathlib import Path\nfrom image_processing.upscale import upscale_image\nfrom image_processing.mask import generate_mask\nfrom image_processing.smart_crop import smart_crop\nimport cv2\n\n# Directories\nINPUT_IMAGES_DIR = Path(\"/kaggle/working/outputs/images\")\nUPSCALED_DIR = Path(\"/kaggle/working/outputs/images_upscaled\")\nMASKS_DIR = Path(\"/kaggle/working/outputs/masks\")\nFINAL_DIR = Path(\"/kaggle/working/outputs/images_final\")\n\n# Ensure output dirs exist\nUPSCALED_DIR.mkdir(parents=True, exist_ok=True)\nMASKS_DIR.mkdir(parents=True, exist_ok=True)\nFINAL_DIR.mkdir(parents=True, exist_ok=True)\n\n# Process every extracted image\nfor img_path in INPUT_IMAGES_DIR.glob(\"*\"):\n    print(f\"\\nProcessing: {img_path.name}\")\n\n    # Upscale (Real-ESRGAN)\n    upscaled_path = upscale_image(\n        image_path=img_path,\n        output_dir=UPSCALED_DIR\n    )\n\n    #  Generate U-2-Net mask\n    mask_path = generate_mask(\n        image_path=upscaled_path,\n        output_dir=MASKS_DIR\n    )\n\n    #  Smart crop\n    final_img = smart_crop(\n        image_path=str(upscaled_path),\n        mask_path=str(mask_path),\n        target_ratio=16/9\n    )\n\n    #  Save final image\n    final_out = FINAL_DIR / img_path.name\n    cv2.imwrite(str(final_out), final_img)\n\n    print(f\" Final image saved: {final_out}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T18:02:16.30591Z","iopub.execute_input":"2025-12-22T18:02:16.306542Z","iopub.status.idle":"2025-12-22T18:05:29.241328Z","shell.execute_reply.started":"2025-12-22T18:02:16.306522Z","shell.execute_reply":"2025-12-22T18:05:29.240534Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"now using the stable diffusion v1.5 (fine tuned using LoRA using kohya_ss notebook)for background generation using the prompt from LLM","metadata":{}},{"cell_type":"code","source":"# 1. Upgrading the conflicting library\n!pip install peft==0.10.0 --upgrade\n\n# 2. Install your required libraries\n!pip install \\\n  diffusers==0.25.1 \\\n  transformers==4.36.2 \\\n  accelerate==0.25.0 \\\n  huggingface_hub==0.20.3 \\\n  safetensors==0.4.2\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T18:05:29.24222Z","iopub.execute_input":"2025-12-22T18:05:29.242564Z","iopub.status.idle":"2025-12-22T18:05:47.055465Z","shell.execute_reply.started":"2025-12-22T18:05:29.242542Z","shell.execute_reply":"2025-12-22T18:05:47.054775Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport accelerate.utils.memory as mem\nfrom diffusers import StableDiffusionPipeline\n\n# --- 1. Apply the Cache Patch (Keep this if your environment needs it) ---\nif not hasattr(mem, \"clear_device_cache\"):\n    def clear_device_cache():\n        torch.cuda.empty_cache() # Explicitly empty torch cache\n    mem.clear_device_cache = clear_device_cache\nprint(\"Patched clear_device_cache ✔\")\n\n# --- 2. Load the Pipeline ---\nmodel_id = \"runwayml/stable-diffusion-v1-5\"\n\npipe = StableDiffusionPipeline.from_pretrained(\n    model_id,\n    torch_dtype=torch.float16,\n    safety_checker=None, # Warning: Be careful with generated content\n    use_safetensors=True # Recommended for speed and safety\n).to(\"cuda\")\n\n\n\nprint(\"Pipeline loaded successfully ✔\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T18:05:47.056441Z","iopub.execute_input":"2025-12-22T18:05:47.056713Z","iopub.status.idle":"2025-12-22T18:07:04.589194Z","shell.execute_reply.started":"2025-12-22T18:05:47.05669Z","shell.execute_reply":"2025-12-22T18:07:04.588053Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"loading our weights which we had get after finetuning","metadata":{}},{"cell_type":"code","source":"pipe.load_lora_weights(\n    \"/kaggle/input/weight/last.safetensors\"\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T18:07:04.589786Z","iopub.status.idle":"2025-12-22T18:07:04.590069Z","shell.execute_reply.started":"2025-12-22T18:07:04.589914Z","shell.execute_reply":"2025-12-22T18:07:04.589929Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\n\nwith open(\"/kaggle/working/outputs/style_token.json\", \"r\") as f:\n    style_token = json.load(f)\n\nbg_prompt = style_token[\"background_prompt\"]\nprint(bg_prompt)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T18:07:04.591458Z","iopub.status.idle":"2025-12-22T18:07:04.591788Z","shell.execute_reply.started":"2025-12-22T18:07:04.591614Z","shell.execute_reply":"2025-12-22T18:07:04.59163Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image = pipe(\n    prompt=bg_prompt,\n    negative_prompt=(\n        \"text, letters, words, logo, watermark, \"\n        \"people, faces, objects, icons\"\n    ),\n    num_inference_steps=25,\n    guidance_scale=7.5,\n    height=544,\n    width=544\n).images[0]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T18:07:04.59286Z","iopub.status.idle":"2025-12-22T18:07:04.593119Z","shell.execute_reply.started":"2025-12-22T18:07:04.592969Z","shell.execute_reply":"2025-12-22T18:07:04.592978Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from pathlib import Path\n\nbg_dir = Path(\"/kaggle/working/outputs/backgrounds\")\nbg_dir.mkdir(parents=True, exist_ok=True)\n\nbg_path = bg_dir / \"slide_background.png\"\nimage.save(bg_path)\n\nprint(\"Background saved:\", bg_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T18:07:04.594123Z","iopub.status.idle":"2025-12-22T18:07:04.594431Z","shell.execute_reply.started":"2025-12-22T18:07:04.594278Z","shell.execute_reply":"2025-12-22T18:07:04.594311Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from image_processing.upscale import upscale_image\n\nback_img = \"/kaggle/working/outputs/backgrounds/slide_background.png\"\n\nupscaled = upscale_image(\n    image_path=back_img,\n    output_dir=\"/kaggle/working/outputs/backgrounds\"\n)\n\nprint(\"Upscaled image:\", upscaled)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T18:07:04.596171Z","iopub.status.idle":"2025-12-22T18:07:04.596596Z","shell.execute_reply.started":"2025-12-22T18:07:04.596414Z","shell.execute_reply":"2025-12-22T18:07:04.596431Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}